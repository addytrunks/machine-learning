{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 09:04:49.036162: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738487089.109519    1598 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738487089.128271    1598 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-02 09:04:49.288378: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1738487093.174536    1598 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "ds = tfds.load('fashion_mnist',split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 09:04:53.320143: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-02-02 09:04:53.330400: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-02-02 09:04:53.358066: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 18],\n",
       "         [ 77],\n",
       "         [227],\n",
       "         [227],\n",
       "         [208],\n",
       "         [210],\n",
       "         [225],\n",
       "         [216],\n",
       "         [ 85],\n",
       "         [ 32],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 61],\n",
       "         [100],\n",
       "         [ 97],\n",
       "         [ 80],\n",
       "         [ 57],\n",
       "         [117],\n",
       "         [227],\n",
       "         [238],\n",
       "         [115],\n",
       "         [ 49],\n",
       "         [ 78],\n",
       "         [106],\n",
       "         [108],\n",
       "         [ 71],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 81],\n",
       "         [105],\n",
       "         [ 80],\n",
       "         [ 69],\n",
       "         [ 72],\n",
       "         [ 64],\n",
       "         [ 44],\n",
       "         [ 21],\n",
       "         [ 13],\n",
       "         [ 44],\n",
       "         [ 69],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 80],\n",
       "         [114],\n",
       "         [ 80],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 26],\n",
       "         [ 92],\n",
       "         [ 69],\n",
       "         [ 68],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 71],\n",
       "         [ 74],\n",
       "         [ 83],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 78],\n",
       "         [ 74],\n",
       "         [ 74],\n",
       "         [ 83],\n",
       "         [ 77],\n",
       "         [108],\n",
       "         [ 34],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 55],\n",
       "         [ 92],\n",
       "         [ 69],\n",
       "         [ 74],\n",
       "         [ 74],\n",
       "         [ 71],\n",
       "         [ 71],\n",
       "         [ 77],\n",
       "         [ 69],\n",
       "         [ 66],\n",
       "         [ 75],\n",
       "         [ 74],\n",
       "         [ 77],\n",
       "         [ 80],\n",
       "         [ 80],\n",
       "         [ 78],\n",
       "         [ 94],\n",
       "         [ 63],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 63],\n",
       "         [ 95],\n",
       "         [ 66],\n",
       "         [ 68],\n",
       "         [ 72],\n",
       "         [ 72],\n",
       "         [ 69],\n",
       "         [ 72],\n",
       "         [ 74],\n",
       "         [ 74],\n",
       "         [ 74],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 80],\n",
       "         [ 77],\n",
       "         [106],\n",
       "         [ 61],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 80],\n",
       "         [108],\n",
       "         [ 71],\n",
       "         [ 69],\n",
       "         [ 72],\n",
       "         [ 71],\n",
       "         [ 69],\n",
       "         [ 72],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 72],\n",
       "         [ 72],\n",
       "         [ 75],\n",
       "         [ 78],\n",
       "         [ 72],\n",
       "         [ 85],\n",
       "         [128],\n",
       "         [ 64],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 88],\n",
       "         [120],\n",
       "         [ 75],\n",
       "         [ 74],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 72],\n",
       "         [ 77],\n",
       "         [ 74],\n",
       "         [ 74],\n",
       "         [ 77],\n",
       "         [ 78],\n",
       "         [ 83],\n",
       "         [ 83],\n",
       "         [ 66],\n",
       "         [111],\n",
       "         [123],\n",
       "         [ 78],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 85],\n",
       "         [134],\n",
       "         [ 74],\n",
       "         [ 85],\n",
       "         [ 69],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 74],\n",
       "         [ 75],\n",
       "         [ 74],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 81],\n",
       "         [ 75],\n",
       "         [ 61],\n",
       "         [151],\n",
       "         [115],\n",
       "         [ 91],\n",
       "         [ 12],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 10],\n",
       "         [ 85],\n",
       "         [153],\n",
       "         [ 83],\n",
       "         [ 80],\n",
       "         [ 68],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 74],\n",
       "         [ 75],\n",
       "         [ 74],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 80],\n",
       "         [ 68],\n",
       "         [ 61],\n",
       "         [162],\n",
       "         [122],\n",
       "         [ 78],\n",
       "         [  6],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 30],\n",
       "         [ 75],\n",
       "         [154],\n",
       "         [ 85],\n",
       "         [ 80],\n",
       "         [ 71],\n",
       "         [ 80],\n",
       "         [ 72],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 78],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 49],\n",
       "         [191],\n",
       "         [132],\n",
       "         [ 72],\n",
       "         [ 15],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 58],\n",
       "         [ 66],\n",
       "         [174],\n",
       "         [115],\n",
       "         [ 66],\n",
       "         [ 77],\n",
       "         [ 80],\n",
       "         [ 72],\n",
       "         [ 78],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 78],\n",
       "         [ 78],\n",
       "         [ 77],\n",
       "         [ 66],\n",
       "         [ 49],\n",
       "         [222],\n",
       "         [131],\n",
       "         [ 77],\n",
       "         [ 37],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 69],\n",
       "         [ 55],\n",
       "         [179],\n",
       "         [139],\n",
       "         [ 55],\n",
       "         [ 92],\n",
       "         [ 74],\n",
       "         [ 74],\n",
       "         [ 78],\n",
       "         [ 74],\n",
       "         [ 78],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 80],\n",
       "         [ 64],\n",
       "         [ 55],\n",
       "         [242],\n",
       "         [111],\n",
       "         [ 95],\n",
       "         [ 44],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 74],\n",
       "         [ 57],\n",
       "         [159],\n",
       "         [180],\n",
       "         [ 55],\n",
       "         [ 92],\n",
       "         [ 64],\n",
       "         [ 72],\n",
       "         [ 74],\n",
       "         [ 74],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 78],\n",
       "         [ 55],\n",
       "         [ 66],\n",
       "         [255],\n",
       "         [ 97],\n",
       "         [108],\n",
       "         [ 49],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 74],\n",
       "         [ 66],\n",
       "         [145],\n",
       "         [153],\n",
       "         [ 72],\n",
       "         [ 83],\n",
       "         [ 58],\n",
       "         [ 78],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 72],\n",
       "         [ 80],\n",
       "         [ 30],\n",
       "         [132],\n",
       "         [255],\n",
       "         [ 37],\n",
       "         [122],\n",
       "         [ 60],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 80],\n",
       "         [ 69],\n",
       "         [142],\n",
       "         [180],\n",
       "         [142],\n",
       "         [ 57],\n",
       "         [ 64],\n",
       "         [ 78],\n",
       "         [ 74],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 72],\n",
       "         [ 85],\n",
       "         [ 21],\n",
       "         [185],\n",
       "         [227],\n",
       "         [ 37],\n",
       "         [143],\n",
       "         [ 63],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 83],\n",
       "         [ 71],\n",
       "         [136],\n",
       "         [194],\n",
       "         [126],\n",
       "         [ 46],\n",
       "         [ 69],\n",
       "         [ 75],\n",
       "         [ 72],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 74],\n",
       "         [ 78],\n",
       "         [ 38],\n",
       "         [139],\n",
       "         [185],\n",
       "         [ 60],\n",
       "         [151],\n",
       "         [ 58],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  4],\n",
       "         [ 81],\n",
       "         [ 74],\n",
       "         [145],\n",
       "         [177],\n",
       "         [ 78],\n",
       "         [ 49],\n",
       "         [ 74],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 74],\n",
       "         [ 72],\n",
       "         [ 63],\n",
       "         [ 80],\n",
       "         [156],\n",
       "         [117],\n",
       "         [153],\n",
       "         [ 55],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 10],\n",
       "         [ 80],\n",
       "         [ 72],\n",
       "         [157],\n",
       "         [163],\n",
       "         [ 61],\n",
       "         [ 55],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 71],\n",
       "         [ 60],\n",
       "         [ 98],\n",
       "         [156],\n",
       "         [132],\n",
       "         [ 58],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 13],\n",
       "         [ 77],\n",
       "         [ 74],\n",
       "         [157],\n",
       "         [143],\n",
       "         [ 43],\n",
       "         [ 61],\n",
       "         [ 72],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 74],\n",
       "         [ 77],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 71],\n",
       "         [ 58],\n",
       "         [ 80],\n",
       "         [157],\n",
       "         [120],\n",
       "         [ 66],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 18],\n",
       "         [ 81],\n",
       "         [ 74],\n",
       "         [156],\n",
       "         [114],\n",
       "         [ 35],\n",
       "         [ 72],\n",
       "         [ 71],\n",
       "         [ 75],\n",
       "         [ 78],\n",
       "         [ 72],\n",
       "         [ 66],\n",
       "         [ 80],\n",
       "         [ 78],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 64],\n",
       "         [ 63],\n",
       "         [165],\n",
       "         [119],\n",
       "         [ 68],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 23],\n",
       "         [ 85],\n",
       "         [ 81],\n",
       "         [177],\n",
       "         [ 57],\n",
       "         [ 52],\n",
       "         [ 77],\n",
       "         [ 71],\n",
       "         [ 78],\n",
       "         [ 80],\n",
       "         [ 72],\n",
       "         [ 75],\n",
       "         [ 74],\n",
       "         [ 77],\n",
       "         [ 77],\n",
       "         [ 75],\n",
       "         [ 64],\n",
       "         [ 37],\n",
       "         [173],\n",
       "         [ 95],\n",
       "         [ 72],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 26],\n",
       "         [ 81],\n",
       "         [ 86],\n",
       "         [160],\n",
       "         [ 20],\n",
       "         [ 75],\n",
       "         [ 77],\n",
       "         [ 77],\n",
       "         [ 80],\n",
       "         [ 78],\n",
       "         [ 80],\n",
       "         [ 89],\n",
       "         [ 78],\n",
       "         [ 81],\n",
       "         [ 83],\n",
       "         [ 80],\n",
       "         [ 74],\n",
       "         [ 20],\n",
       "         [177],\n",
       "         [ 77],\n",
       "         [ 74],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 49],\n",
       "         [ 77],\n",
       "         [ 91],\n",
       "         [200],\n",
       "         [  0],\n",
       "         [ 83],\n",
       "         [ 95],\n",
       "         [ 86],\n",
       "         [ 88],\n",
       "         [ 88],\n",
       "         [ 89],\n",
       "         [ 88],\n",
       "         [ 89],\n",
       "         [ 88],\n",
       "         [ 83],\n",
       "         [ 89],\n",
       "         [ 86],\n",
       "         [  0],\n",
       "         [191],\n",
       "         [ 78],\n",
       "         [ 80],\n",
       "         [ 24],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 54],\n",
       "         [ 71],\n",
       "         [108],\n",
       "         [165],\n",
       "         [  0],\n",
       "         [ 24],\n",
       "         [ 57],\n",
       "         [ 52],\n",
       "         [ 57],\n",
       "         [ 60],\n",
       "         [ 60],\n",
       "         [ 60],\n",
       "         [ 63],\n",
       "         [ 63],\n",
       "         [ 77],\n",
       "         [ 89],\n",
       "         [ 52],\n",
       "         [  0],\n",
       "         [211],\n",
       "         [ 97],\n",
       "         [ 77],\n",
       "         [ 61],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 68],\n",
       "         [ 91],\n",
       "         [117],\n",
       "         [137],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 18],\n",
       "         [216],\n",
       "         [ 94],\n",
       "         [ 97],\n",
       "         [ 57],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 54],\n",
       "         [115],\n",
       "         [105],\n",
       "         [185],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  1],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [153],\n",
       "         [ 78],\n",
       "         [106],\n",
       "         [ 37],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       " \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [ 18],\n",
       "         [ 61],\n",
       "         [ 41],\n",
       "         [103],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [106],\n",
       "         [ 47],\n",
       "         [ 69],\n",
       "         [ 23],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]]], dtype=uint8),\n",
       " 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.as_numpy_iterator().next()['image'],ds.as_numpy_iterator().next()['label'],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise dataset and build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2800x2800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(ncols=4,figsize=(28,28))\n",
    "for idx in range(4):\n",
    "    sample_image = data_iterator.next()\n",
    "    ax[idx].imshow(np.squeeze(sample_image['image']))\n",
    "    ax[idx].title.set_text(sample_image['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_images(data):\n",
    "    image = data['image']\n",
    "    return image//255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(scale_images) # Applies a transformation function\n",
    "ds = ds.cache() # Caches the dataset in memory (RAM) to speed up training\n",
    "ds = ds.shuffle(60000) # Randomly shuffles the dataset to prevent the model from learning the order of images.\n",
    "ds = ds.batch(128) # Self explanatory DUH\n",
    "ds = ds.prefetch(64) # Prepares the next batch of data while the model is training on the current batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.as_numpy_iterator().next().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Flatten,Reshape,LeakyReLU,Dropout,UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    1 Generator starts with a 128D random noise vector.\n",
    "    2 Dense layer reshapes it into a 77128 low-resolution feature map.\n",
    "    3 Upsampling layers progressively increase resolution to 2828.\n",
    "    4 Final Conv2D layer produces a grayscale image (28281).\n",
    "    5 No activation on the last layer  Raw pixel values.\n",
    "\n",
    "    NOTE: LeakyRELU recommended for building GANs\n",
    "\n",
    "     This generator is designed to create 2828 grayscale images from random noise!\n",
    "'''\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(7*7*128, input_dim=128))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Reshape((7,7,128)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,5,padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,5,padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Conv2D(128,4,padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Conv2D(128,4,padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Conv2D(1,4,padding='same',activation='sigmoid'))\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">809,088</span> \n",
       "\n",
       " leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">409,728</span> \n",
       "\n",
       " leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">409,728</span> \n",
       "\n",
       " leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> \n",
       "\n",
       " leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> \n",
       "\n",
       " leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)                  \u001b[38;5;34m809,088\u001b[0m \n",
       "\n",
       " leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " reshape (\u001b[38;5;33mReshape\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m409,728\u001b[0m \n",
       "\n",
       " leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m409,728\u001b[0m \n",
       "\n",
       " leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m262,272\u001b[0m \n",
       "\n",
       " leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m262,272\u001b[0m \n",
       "\n",
       " leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)               \u001b[38;5;34m2,049\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,155,137</span> (8.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,155,137\u001b[0m (8.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,155,137</span> (8.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,155,137\u001b[0m (8.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32,5,input_shape=(28,28,1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(64,5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128,5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256,5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> \n",
       "\n",
       " leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> \n",
       "\n",
       " leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> \n",
       "\n",
       " leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> \n",
       "\n",
       " leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">36,865</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m832\u001b[0m \n",
       "\n",
       " leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m51,264\u001b[0m \n",
       "\n",
       " leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m204,928\u001b[0m \n",
       "\n",
       " leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m819,456\u001b[0m \n",
       "\n",
       " leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_3 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_4 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                      \u001b[38;5;34m36,865\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,113,345</span> (4.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,113,345\u001b[0m (4.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,113,345</span> (4.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,113,345\u001b[0m (4.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = Adam(learning_rate=0.0001)\n",
    "d_opt = Adam(learning_rate=0.00001)\n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionGAN(Model):\n",
    "    def __init__(self,generator,discriminator,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        \n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def compile(self,g_opt,d_opt,g_loss,d_loss,*args,**kwargs):\n",
    "        super().compile(*args,**kwargs)\n",
    "\n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss\n",
    "    \n",
    "    def train_step(self,batch):\n",
    "        real_images = batch\n",
    "        fake_images = self.generator(tf.random.normal((128,128,1)),training=False)\n",
    "\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            yhat_real = self.discriminator(real_images, training=True) \n",
    "            yhat_fake = self.discriminator(fake_images, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "\n",
    "             # Create labels for real and fakes images\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "            \n",
    "            # Add some noise to the TRUE outputs\n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "            \n",
    "            # Calculate loss - BINARYCROSS \n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "       \n",
    "        # Apply backpropagation - nn learn \n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables) \n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "        \n",
    "        # Train the generator \n",
    "        with tf.GradientTape() as g_tape: \n",
    "            # Generate some new images\n",
    "            gen_images = self.generator(tf.random.normal((128,128,1)), training=True)\n",
    "                                        \n",
    "            # Create the predicted labels\n",
    "            predicted_labels = self.discriminator(gen_images, training=False)\n",
    "                                        \n",
    "            # Calculate loss - trick to training to fake out the discriminator\n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels) \n",
    "            \n",
    "        # Apply backprop\n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of subclassed model\n",
    "fashgan = FashionGAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "fashgan.compile(g_opt, d_opt, g_loss, d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('images', f'generated_img_{epoch}_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 43/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14:07\u001b[0m 2s/step - d_loss: 0.6937 - g_loss: 0.6968"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mfashgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mModelMonitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = fashgan.fit(ds, epochs=20, callbacks=[ModelMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Loss')\n",
    "plt.plot(hist.history['d_loss'], label='d_loss')\n",
    "plt.plot(hist.history['g_loss'], label='g_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights(os.path.join('archive', 'generatormodel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = generator.predict(tf.random.normal((16, 128, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(10,10))\n",
    "for r in range(4): \n",
    "    for c in range(4): \n",
    "        ax[r][c].imshow(imgs[(r+1)*(c+1)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('generator.h5')\n",
    "discriminator.save('discriminator.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
